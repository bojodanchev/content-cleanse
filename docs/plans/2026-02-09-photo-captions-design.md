# Photo Captions Feature - Design Document

**Date**: 2026-02-09
**Status**: Approved

## Overview

Add a "Photo Captions" feature to Content Cleanse. Users upload a photo and receive multiple captioned image variants — each with a different caption burned in. Captions can be entered manually or generated by AI (niche-based or image-aware). Users can optionally generate a slideshow video from the captioned images.

## User Flow

1. **Upload** — User uploads a single photo (JPG/PNG, max 10MB). Dropzone shows preview.
2. **Captions** — User chooses caption mode:
   - **Manual**: Text area, one caption per line. Each line = one variant.
   - **AI Generated**: Select niche (nurse, gym, mom, finance, etc.), style (drama, listicle, cliffhanger, mixed), and count (10, 25, 50). Captions appear in an editable list for review/edit/delete before proceeding.
3. **Settings** — Font size (small/medium/large), position (top/center/bottom), confirm variant count. Preview thumbnail.
4. **Processing** — Progress bar. On completion: download ZIP of images. Optional "Generate Slideshow Video" button.

Plan limits apply the same way — Free: 5 jobs, Pro: 100, Agency: unlimited. Each photo caption job counts as one job against quota.

## Architecture

### Processing Pipeline

1. Frontend uploads photo to Supabase Storage (`images/{userId}/{jobId}/{filename}`)
2. Creates job record with `job_type: 'photo_captions'`
3. Calls `/api/jobs/process-captions` endpoint
4. Modal worker downloads photo, loops through captions:
   - Resize/crop to 1080x1920 (9:16 vertical)
   - Render caption with Pillow (white text, black stroke, word-wrapped)
   - Apply light augmentation (brightness, saturation, color tint)
   - Strip metadata
   - Upload variant to Supabase Storage
5. If slideshow requested: FFmpeg composites images with xfade transitions
6. ZIP all outputs, mark job completed

### AI Caption Generation

Happens before processing on a separate API route (`/api/captions/generate`). Uses OpenAI GPT-4o-mini. Two modes:
- **Niche-based**: Prompt templates with niche + style → viral captions (ported from slideshow captions project)
- **Image-aware**: Send photo to vision model → contextual captions

Returns captions to frontend for user review/editing. Captions only sent to Modal worker after user confirms.

## Data Model Changes

### Migration: `008_photo_captions.sql`

**Jobs table** — add column:
- `job_type TEXT NOT NULL DEFAULT 'video'` — values: `'video'` | `'photo_captions'`

**Variants table** — add column:
- `caption_text TEXT` — nullable. The caption burned into that variant. Null for video variants.

### Jobs Settings JSON (photo_captions type)

```json
{
  "captions": ["caption one", "caption two"],
  "font_size": "medium",
  "position": "center",
  "generate_video": false,
  "caption_source": "manual",
  "ai_niche": "nurse",
  "ai_style": "mixed"
}
```

### Storage Paths

- Source photos: `images/{userId}/{jobId}/{filename}`
- Output images: `outputs/{userId}/{jobId}/variant_001.png`
- Output video: `outputs/{userId}/{jobId}/slideshow.mp4`
- ZIP: `outputs/{userId}/{jobId}/variants.zip`

No changes to profiles, payments, watermarks, or events tables.

## Text Rendering

Ported from slideshow captions project (`text_renderer.py`):

- **Font**: Anton bold (bundled TTF)
- **Text color**: White
- **Stroke**: Black, 3px
- **Text transform**: UPPERCASE
- **Word wrap**: 90% of image width
- **Font sizes**: small=60px, medium=80px, large=100px
- **Position**: top=10% from top, center=50%, bottom=90%

## Light Augmentation

Per variant (no geometric transforms):

| Transform | Range |
|-----------|-------|
| Brightness | ±5% |
| Saturation | ±5% |
| Color tint | ±3 per RGB channel |
| JPEG quality | 85-95 (randomized) |
| Metadata | Stripped (EXIF/ICC/XMP) |

No rotation, zoom, or crop.

## Slideshow Video (Optional)

Ported from slideshow captions project (`video_generator.py`):

- FFmpeg xfade transitions (slideleft, 0.2s duration)
- 2 second pause per slide
- 1080x1920, H.264, 30fps
- Metadata stripped
- CRF 18, AAC audio not applicable (images only)

## New Files

### Frontend

| File | Purpose |
|------|---------|
| `src/app/(dashboard)/captions/page.tsx` | Main captions page (4-step state machine) |
| `src/components/captions/caption-editor.tsx` | Manual caption list editor |
| `src/components/captions/ai-caption-form.tsx` | Niche/style/count selector + generate button |
| `src/components/captions/caption-settings.tsx` | Font size, position controls + preview |
| `src/app/api/captions/generate/route.ts` | OpenAI caption generation endpoint |
| `src/app/api/jobs/process-captions/route.ts` | Triggers Modal caption processing |

### Backend (Modal Worker)

| File | Purpose |
|------|---------|
| `src/workers/process-video/text_renderer.py` | Pillow text rendering (port from slideshow captions) |
| `src/workers/process-video/image_augmenter.py` | Light augmentation + metadata strip |

### Database

| File | Purpose |
|------|---------|
| `supabase/migrations/008_photo_captions.sql` | Adds `job_type` to jobs, `caption_text` to variants |

## Modified Files

| File | Change |
|------|--------|
| `src/workers/process-video/main.py` | Add `process_captions()` endpoint, add Pillow to container image |
| `src/app/(dashboard)/layout.tsx` | Add "Photo Captions" link to sidebar nav |
| `src/lib/supabase/types.ts` | Add `job_type`, `caption_text` to TypeScript types |
| `src/lib/modal/client.ts` | Add `triggerCaptionProcessing()` function |

## Environment Variables

New:
- `OPENAI_API_KEY` — for AI caption generation

## Plan Enforcement

Same as video jobs:
- Job counts against `quota_used` (1 per photo caption job)
- No separate photo quota
- Plan variant limits apply: Free=10, Pro=100, Agency=100

## Out of Scope

- Custom fonts (beyond bundled Anton)
- Custom text colors
- Draggable text positioning
- Multi-photo batch upload
- Caption templates/presets
- Geometric augmentation (rotation, zoom, crop)
